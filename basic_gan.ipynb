{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "A8cLqx0nABAo"
      },
      "outputs": [],
      "source": [
        "# import the libraries\n",
        "\n",
        "import torch, pdb # pdb is for debugging\n",
        "from torch.utils.data import DataLoader # build iterable training data\n",
        "from torch import nn # build deep learning architectures and models\n",
        "from torchvision import transforms # allow us to transform our data in different ways\n",
        "from torchvision.datasets import MNIST # dataset composed of images of numbers\n",
        "from torchvision.utils import make_grid # to build a grid of images to evaluate during the training\n",
        "from tqdm.auto import tqdm # for the bar showing the progress of the process\n",
        "import matplotlib.pyplot as plt # plot image with all the visuals that we want"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we want to show a grid with a number of generated images vs. real images\n",
        "# so we need some way to basically visualise this grid\n",
        "\n",
        "# visualisation function\n",
        "def show_tensor_images(image_tensor, ch=1, num_images=25, size=(28, 28)):\n",
        "  # to detach image tensor from all the gradient computations and pass it to the cpu (we will use gpu for training)\n",
        "  # tensor: 128 x 784(28x28)\n",
        "  # put everyting into a new data\n",
        "  data = image_tensor.detach().cpu().view(-1,ch,*size) # 128 x 1 x 28 x 28\n",
        "  # create the grid\n",
        "  grid = make_grid(data[:num_images], nrow=5).permute(1, 2, 0) # 1 x 28 x 28 --> permute : 28 x 28 x 1\n",
        "  plt.imshow(grid)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "RMnGSHiDBS-s"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup of the main parameters\n",
        "\n",
        "epochs = 500 # number of cycles in training\n",
        "cur_step = 0 # each of step we process one batch\n",
        "info_step = 300 # within an epoch, each step processes a batch\n",
        "mean_gen_loss = 0 # mean generator loss\n",
        "mean_disc_loss = 0 # mean discriminator loss\n",
        "\n",
        "# some hyperparameters\n",
        "\n",
        "z_dim = 64 # the dimensionality of the noise vector that is the input of the generator\n",
        "lr = 0.00001 # learning rate\n",
        "loss_func = nn.BCEWithLogitsLoss() # loss function, takes the logits and apply them all at once to a sigmoid function that is gonna set the range [0,1]\n",
        "\n",
        "bs = 128 # batch size, how many images to be processed in the GPU\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\") # selecting current device to do the processing\n",
        "\n",
        "# dataloader is going to hold our training data\n",
        "dataloader = DataLoader(\n",
        "    MNIST('.', download=True, transform=transforms.ToTensor()), # root folder, download it, transform data into multi-dimensional tensor\n",
        "    batch_size = bs,\n",
        "    shuffle = True) # every epoch reorder data\n",
        "\n",
        "# number of steps = 60000 (MNIST size) / 128 = 468.75 almost 469"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wy-pSc_4J0-L",
        "outputId": "94a9e2ea-16d0-48f6-a1ef-80730395861a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 11.5MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 338kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 2.72MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.17MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# declare our models\n",
        "\n",
        "# generator\n",
        "def genBlock(inp, out): # generator block with the size of input and the size of the output\n",
        "  return nn.Sequential( # basically set a number of layers that are gonna be executed sequentially\n",
        "      nn.Linear(inp, out), # a linear computation between input and output\n",
        "      nn.BatchNorm1d(out), # 1D because we are using black & white and one dimemsioal images with a single channel, normalise the values that are coming from the previous layer\n",
        "      nn.ReLU(inplace = True) # add non-linearity: in order to learn more complex functions\n",
        "  )\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, z_dim = 64, i_dim = 784, h_dim = 128): # latent vector, output image size 28x28=784, base size of the hidden layer of the generator\n",
        "    super().__init__()\n",
        "    self.gen = nn.Sequential(\n",
        "        genBlock(z_dim, h_dim), # 64 -> 128\n",
        "        genBlock(h_dim, h_dim * 2), # 128 -> 256 we want to increase the size\n",
        "        genBlock(h_dim * 2, h_dim * 4), # 256 -> 512 incresing the size\n",
        "        genBlock(h_dim * 4, h_dim * 8), # 512 -> 1024\n",
        "        nn.Linear(h_dim * 8, i_dim), # 1024 -> 784(28x28) we want to create an image with the same size of the MNIST images\n",
        "        nn.Sigmoid() # set values [0,1]\n",
        "    )\n",
        "\n",
        "  def forward(self, noise): # the function that is gonna be executed when we basically run the instance of the class\n",
        "    return self.gen(noise)\n",
        "\n",
        "def gen_noise(number, z_dim): # the function that generates noise\n",
        "  return torch.randn(number, z_dim).to(device) # returns a tensor field with random numbers from a normal dist. with mean of 0 and variance of 1 (standard normal distribution)\n",
        "\n",
        "############################# ##########################\n",
        "\n",
        "# discriminator\n",
        "def discBlock(inp, out): # like generator\n",
        "  return nn.Sequential(\n",
        "    nn.Linear(inp, out),\n",
        "    nn.LeakyReLU(0.2, inplace = True) # instead of giving 0 to negative values give them a small negative value on a slope\n",
        "  )\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, i_dim = 784, h_dim = 256):\n",
        "    super().__init__()\n",
        "    self.disc = nn.Sequential(\n",
        "        discBlock(i_dim, h_dim * 4), # 784 -> 1024\n",
        "        discBlock(h_dim * 4, h_dim * 2), # 1024 - > 512\n",
        "        discBlock(h_dim * 2, h_dim), # 512 -> 256\n",
        "        nn.Linear(h_dim * 32, 1) # 256 -> 1\n",
        "    )\n",
        "  def forward(self, image): # takes the image\n",
        "    return self.disc(image) # result of passing that image to the discriminator module\n"
      ],
      "metadata": {
        "id": "PfVDOPjkKD_R"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4AXvN4myUYBc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}