{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R95JTPCe2Sx9",
        "outputId": "206d4654-ea83-460f-d076-a5d7e3215e90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CLIP'...\n",
            "remote: Enumerating objects: 256, done.\u001b[K\n",
            "remote: Total 256 (delta 0), reused 0 (delta 0), pack-reused 256 (from 1)\u001b[K\n",
            "Receiving objects: 100% (256/256), 8.93 MiB | 6.25 MiB/s, done.\n",
            "Resolving deltas: 100% (133/133), done.\n",
            "Cloning into 'taming-transformers'...\n",
            "remote: Enumerating objects: 1342, done.\u001b[K\n",
            "remote: Counting objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 1342 (delta 0), reused 0 (delta 0), pack-reused 1341 (from 2)\u001b[K\n",
            "Receiving objects: 100% (1342/1342), 409.77 MiB | 15.33 MiB/s, done.\n",
            "Resolving deltas: 100% (282/282), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/openai/CLIP.git\n",
        "# CLIP: Contrastive Language-Image Pre-Training\n",
        "# Learning Transferable Visual Models From Natural Language Supervision (paper)\n",
        "\n",
        "!git clone https://github.com/CompVis/taming-transformers.git\n",
        "# Taming Transformers for High-Resolutions Image Synthesis (paper)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install some extra libraries\n",
        "\n",
        "!pip install --no-deps ftfy regex tqdm  # install text fixing, regex, and progress bar libraries without dependencies\n",
        "!pip install omegaconf==2.0.0 pytorch-lightning==1.0.8  # install specific versions for configuration and training framework\n",
        "!pip uninstall torchtext --yes  # remove torchtext as it may conflict or is not needed\n",
        "!pip install einop  # install einop, a lightweight wrapper for Einstein summation operations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4N7Iol67_9o",
        "outputId": "214b682c-0864-4032-ac7c-c987844e9a2b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ftfy\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ftfy\n",
            "Successfully installed ftfy-6.3.1\n",
            "Collecting omegaconf==2.0.0\n",
            "  Downloading omegaconf-2.0.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting pytorch-lightning==1.0.8\n",
            "  Downloading pytorch_lightning-1.0.8-py3-none-any.whl.metadata (26 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from omegaconf==2.0.0) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from omegaconf==2.0.0) (4.13.2)\n",
            "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.0.8) (2.0.2)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.0.8) (2.6.0+cu124)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.0.8) (1.0.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.0.8) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.0.8) (2025.3.2)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.0.8) (2.18.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.8) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.8) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.8) (3.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.8) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.8) (5.29.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.8) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.8) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.8) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.8) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-lightning==1.0.8) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-lightning==1.0.8) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-lightning==1.0.8) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.3->pytorch-lightning==1.0.8)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.3->pytorch-lightning==1.0.8)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.3->pytorch-lightning==1.0.8)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.3->pytorch-lightning==1.0.8)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.3->pytorch-lightning==1.0.8)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.3->pytorch-lightning==1.0.8)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.3->pytorch-lightning==1.0.8)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.3->pytorch-lightning==1.0.8)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.3->pytorch-lightning==1.0.8)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-lightning==1.0.8) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-lightning==1.0.8) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-lightning==1.0.8) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.3->pytorch-lightning==1.0.8)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-lightning==1.0.8) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-lightning==1.0.8) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.3->pytorch-lightning==1.0.8) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.2.0->pytorch-lightning==1.0.8) (3.0.2)\n",
            "Downloading omegaconf-2.0.0-py3-none-any.whl (33 kB)\n",
            "Downloading pytorch_lightning-1.0.8-py3-none-any.whl (561 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.4/561.4 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m120.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m108.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: omegaconf, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, pytorch-lightning\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 omegaconf-2.0.0 pytorch-lightning-1.0.8\n",
            "\u001b[33mWARNING: Skipping torchtext as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting einop\n",
            "  Downloading einop-0.0.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: einops>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from einop) (0.8.1)\n",
            "Downloading einop-0.0.1-py3-none-any.whl (3.0 kB)\n",
            "Installing collected packages: einop\n",
            "Successfully installed einop-0.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "\n",
        "import numpy as np  # numerical operations and arrays\n",
        "import torch, os, imageio, pdb, math  # torch for deep learning, os for file paths, imageio for reading/writing images, pdb for debugging, math for mathematical functions\n",
        "import torchvision  # PyTorch vision utilities\n",
        "import torchvision.transforms as T  # image transformations\n",
        "import torchvision.transforms.functional as TF  # functional image transformations\n",
        "\n",
        "import PIL  # Python Imaging Library for handling images\n",
        "import matplotlib.pyplot as plt  # plotting and visualisation\n",
        "\n",
        "import yaml  # for reading YAML configuration files\n",
        "from omegaconf import OmegaConf  # structured configuration management\n",
        "\n",
        "from CLIP import clip  # import CLIP model (Contrastive Language–Image Pretraining)\n",
        "\n",
        "# import warnings\n",
        "# warnings.filterwarnings('ignore')  # (optional) suppress warnings\n"
      ],
      "metadata": {
        "id": "FXrsyf398ZbD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# helper functions\n",
        "\n",
        "def show_from_tensor(tensor):\n",
        "  img = tensor.clone()  # create a copy of the tensor\n",
        "  img = img.mul(255).byte()  # scale pixel values from [0,1] to [0,255] and convert to byte type\n",
        "  img = img.cpu().numpy().transpose((1, 2, 0))  # move to CPU and change to H x W x C format for plotting\n",
        "\n",
        "  plt.figure(figsize=(10, 7))  # set figure size\n",
        "  plt.axis('off')  # remove axes for clean display\n",
        "  plt.imshow(img)  # show image\n",
        "  plt.show()\n",
        "\n",
        "def norm_data(data):\n",
        "  return (data.clip(-1, 1) + 1) / 2  # clip values to [-1, 1] and normalise to [0, 1] range\n",
        "\n",
        "# parameters\n",
        "\n",
        "learning_rate = 0.5  # learning rate for the optimiser\n",
        "batch_size = 1  # number of samples per training iteration\n",
        "wd = 0.1  # weight decay (regularisation parameter)\n",
        "noise_factor = 0.1  # scale of noise added to the image\n",
        "\n",
        "total_iter = 100  # total number of optimisation steps\n",
        "im_shape = [225, 400, 3]  # image dimensions: height, width, channels\n",
        "size1, size2, channels = im_shape  # unpack image dimensions\n"
      ],
      "metadata": {
        "id": "xXwfET8-9GD0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### clip model ###\n",
        "\n",
        "clipmodel, _ = clip.load(\"ViT-B/32\", jit = False)  # load the CLIP model with Vision Transformer (ViT-B/32) architecture\n",
        "clipmodel.eval()  # set the model to evaluation mode\n",
        "print(clip.available_models())  # print all available CLIP model variants\n",
        "\n",
        "print(\"CLIP model visual input resolution: \", clipmodel.visual.input_resolution)  # display expected image resolution\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # choose GPU if available, else CPU\n",
        "torch.cuda.empty_cache()  # clear unused GPU memory"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x75r9ila_eoZ",
        "outputId": "1a6bc31c-bded-42f4-c8ad-dc7ffa89e2fa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 338M/338M [00:03<00:00, 92.1MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['RN50', 'RN101', 'RN50x4', 'RN50x16', 'RN50x64', 'ViT-B/32', 'ViT-B/16', 'ViT-L/14', 'ViT-L/14@336px']\n",
            "CLIP model visual input resolution:  224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## taming transformer instantiation\n",
        "\n",
        "%cd taming-transformers/\n",
        "\n",
        "!mkdir -p models/vqgan_imagenet_f16_16384/checkpoints\n",
        "!mkdir -p models/vqgan_imagenet_f16_16384/configs\n",
        "\n",
        "if len(os.listdir('models/vqgan_imagenet_f16_16384/checkpoints/')) == 0:\n",
        "   !wget 'https://heibox.uni-heidelberg.de/f/867b05fc8c4841768640/?dl=1' -O 'models/vqgan_imagenet_f16_16384/checkpoints/last.ckpt'\n",
        "   !wget 'https://heibox.uni-heidelberg.de/f/274fb24ed38341bfa753/?dl=1' -O 'models/vqgan_imagenet_f16_16384/configs/model.yaml'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OE1M8kVAvRAw",
        "outputId": "ba1bd9ea-8fa8-4108-d7ef-04b1eaaa9673"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/taming-transformers\n",
            "--2025-05-02 08:34:14--  https://heibox.uni-heidelberg.de/f/867b05fc8c4841768640/?dl=1\n",
            "Resolving heibox.uni-heidelberg.de (heibox.uni-heidelberg.de)... 129.206.7.113\n",
            "Connecting to heibox.uni-heidelberg.de (heibox.uni-heidelberg.de)|129.206.7.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://heibox.uni-heidelberg.de/seafhttp/files/03f7bfec-cb7f-4c50-921f-f663c33c67fc/last.ckpt [following]\n",
            "--2025-05-02 08:34:15--  https://heibox.uni-heidelberg.de/seafhttp/files/03f7bfec-cb7f-4c50-921f-f663c33c67fc/last.ckpt\n",
            "Reusing existing connection to heibox.uni-heidelberg.de:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 980092370 (935M) [application/octet-stream]\n",
            "Saving to: ‘models/vqgan_imagenet_f16_16384/checkpoints/last.ckpt’\n",
            "\n",
            "models/vqgan_imagen 100%[===================>] 934.69M  12.6MB/s    in 80s     \n",
            "\n",
            "2025-05-02 08:35:35 (11.6 MB/s) - ‘models/vqgan_imagenet_f16_16384/checkpoints/last.ckpt’ saved [980092370/980092370]\n",
            "\n",
            "--2025-05-02 08:35:35--  https://heibox.uni-heidelberg.de/f/274fb24ed38341bfa753/?dl=1\n",
            "Resolving heibox.uni-heidelberg.de (heibox.uni-heidelberg.de)... 129.206.7.113\n",
            "Connecting to heibox.uni-heidelberg.de (heibox.uni-heidelberg.de)|129.206.7.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://heibox.uni-heidelberg.de/seafhttp/files/a0fd222f-cae7-4277-a728-1b1e95f411ea/model.yaml [following]\n",
            "--2025-05-02 08:35:36--  https://heibox.uni-heidelberg.de/seafhttp/files/a0fd222f-cae7-4277-a728-1b1e95f411ea/model.yaml\n",
            "Reusing existing connection to heibox.uni-heidelberg.de:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 692 [application/octet-stream]\n",
            "Saving to: ‘models/vqgan_imagenet_f16_16384/configs/model.yaml’\n",
            "\n",
            "models/vqgan_imagen 100%[===================>]     692  --.-KB/s    in 0s      \n",
            "\n",
            "2025-05-02 08:35:37 (360 MB/s) - ‘models/vqgan_imagenet_f16_16384/configs/model.yaml’ saved [692/692]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.Inf = np.inf  # patch legacy attribute for libraries that still use np.Inf"
      ],
      "metadata": {
        "id": "dUrUVpURHWfk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from taming.models.vqgan import VQModel  # import the VQModel class from the taming VQGAN implementation\n",
        "\n",
        "def load_config(config_path, display=False):\n",
        "    config_data = OmegaConf.load(config_path)  # load configuration file\n",
        "    if display:\n",
        "        print(yaml.dump(OmegaConf.to_container(config_data)))  # optionally print config content\n",
        "    return config_data  # return the configuration object\n",
        "\n",
        "def load_vqgan(config, ckpt_path=None):  # corrected function name and argument\n",
        "    model = VQModel(**config.model.params)  # initialise the VQGAN model with parameters from the config\n",
        "    if ckpt_path is not None:\n",
        "        state_dict = torch.load(ckpt_path, map_location=\"cpu\", weights_only=False)[\"state_dict\"]  # load model weights from checkpoint\n",
        "        missing, unexpected = model.load_state_dict(state_dict, strict=False)  # allow missing/unexpected keys\n",
        "    return model.eval()  # set to evaluation mode and return the model\n",
        "\n",
        "def generator(x):  # decode a latent tensor using the VQGAN decoder\n",
        "    x = taming_model.post_quant_conv(x)  # apply post-quantisation convolution\n",
        "    x = taming_model.decoder(x)  # decode to image space\n",
        "    return x  # return the generated image tensor\n",
        "\n",
        "# load VQGAN configuration and model\n",
        "taming_config = load_config(\"./models/vqgan_imagenet_f16_16384/configs/model.yaml\", display=True)\n",
        "taming_model = load_vqgan(taming_config, ckpt_path=\"./models/vqgan_imagenet_f16_16384/checkpoints/last.ckpt\").to(device) # move model to GPU/CPU\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8I0Gpg_w_sU",
        "outputId": "e2041701-1b53-4fe5-e83f-d0af76ce8edc",
        "collapsed": true
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model:\n",
            "  base_learning_rate: 4.5e-06\n",
            "  params:\n",
            "    ddconfig:\n",
            "      attn_resolutions:\n",
            "      - 16\n",
            "      ch: 128\n",
            "      ch_mult:\n",
            "      - 1\n",
            "      - 1\n",
            "      - 2\n",
            "      - 2\n",
            "      - 4\n",
            "      double_z: false\n",
            "      dropout: 0.0\n",
            "      in_channels: 3\n",
            "      num_res_blocks: 2\n",
            "      out_ch: 3\n",
            "      resolution: 256\n",
            "      z_channels: 256\n",
            "    embed_dim: 256\n",
            "    lossconfig:\n",
            "      params:\n",
            "        codebook_weight: 1.0\n",
            "        disc_conditional: false\n",
            "        disc_in_channels: 3\n",
            "        disc_num_layers: 2\n",
            "        disc_start: 0\n",
            "        disc_weight: 0.75\n",
            "      target: taming.modules.losses.vqperceptual.VQLPIPSWithDiscriminator\n",
            "    monitor: val/rec_loss\n",
            "    n_embed: 16384\n",
            "  target: taming.models.vqgan.VQModel\n",
            "\n",
            "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:02<00:00, 189MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading vgg_lpips model from https://heibox.uni-heidelberg.de/f/607503859c864bc1b30b/?dl=1 to taming/modules/autoencoder/lpips/vgg.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "8.19kB [00:00, 36.4kB/s]                            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
            "VQLPIPSWithDiscriminator running with hinge loss.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# declare the values that we are going to optimise\n",
        "\n",
        "class Parameters(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Parameters, self).__init__()\n",
        "        self.data = .5 * torch.randn(batch_size, 256, size1//16, size2//16).cuda() # 1x256x14x25 (225//16, 400/16)\n",
        "        self.data = torch.nn.Parameter(torch.sin(self.data))\n",
        "\n",
        "    def forward(self):\n",
        "        return self.data\n",
        "\n",
        "def init_params():\n",
        "  params = Parameters().cuda()\n",
        "  optimiser = torch.optim.AdamW([{'params': [params.data], 'lr': learning_rate}], weight_decay=wd)\n",
        "  return params, optimiser"
      ],
      "metadata": {
        "id": "ZLdoLPElHcrc"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}