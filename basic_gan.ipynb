{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8cLqx0nABAo"
      },
      "outputs": [],
      "source": [
        "# import the libraries\n",
        "\n",
        "import torch, pdb # pdb is for debugging\n",
        "from torch.utils.data import DataLoader # build iterable training data\n",
        "from torch import nn # build deep learning architectures and models\n",
        "from torchvision import transforms # allow us to transform our data in different ways\n",
        "from torchvision.datasets import MNIST # dataset composed of images of numbers\n",
        "from torchvision.utils import make_grid # to build a grid of images to evaluate during the training\n",
        "from tqdm.auto import tqdm # for the bar showing the progress of the process\n",
        "import matplotlib.pyplot as plt # plot image with all the visuals that we want"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we want to show a grid with a number of generated images vs. real images\n",
        "# so we need some way to basically visualise this grid\n",
        "\n",
        "# visualisation function\n",
        "def show_tensor_images(image_tensor, ch=1, num_images=25, size=(28, 28)):\n",
        "  # to detach image tensor from all the gradient computations and pass it to the cpu (we will use gpu for training)\n",
        "  # tensor: 128 x 784(28x28)\n",
        "  # put everyting into a new data\n",
        "  data = image_tensor.detach().cpu().view(-1,ch,*size) # 128 x 1 x 28 x 28\n",
        "  # create the grid\n",
        "  grid = make_grid(data[:num_images], nrow=5).permute(1, 2, 0) # 1 x 28 x 28 --> permute : 28 x 28 x 1\n",
        "  plt.imshow(grid)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "RMnGSHiDBS-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup of the main parameters\n",
        "\n",
        "epochs = 500 # number of cycles in training\n",
        "cur_step = 0 # each of step we process one batch\n",
        "info_step = 300 # within an epoch, each step processes a batch\n",
        "mean_gen_loss = 0 # mean generator loss\n",
        "mean_disc_loss = 0 # mean discriminator loss\n",
        "\n",
        "# some hyperparameters\n",
        "\n",
        "z_dim = 64 # the dimensionality of the noise vector that is the input of the generator\n",
        "lr = 0.00001 # learning rate\n",
        "loss_func = nn.BCEWithLogitsLoss() # loss function, takes the logits and apply them all at once to a sigmoid function that is gonna set the range [0,1]\n",
        "\n",
        "bs = 128 # batch size, how many images to be processed in the GPU\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\") # selecting current device to do the processing\n",
        "\n",
        "# dataloader is going to hold our training data\n",
        "dataloader = DataLoader(\n",
        "    MNIST('.', download=True, transform=transforms.ToTensor()), # root folder, download it, transform data into multi-dimensional tensor\n",
        "    batch_size = bs,\n",
        "    shuffle = True) # every epoch reorder data\n",
        "\n",
        "# number of steps = 60000 (MNIST size) / 128 = 468.75 almost 469"
      ],
      "metadata": {
        "id": "Wy-pSc_4J0-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# declare our models\n",
        "\n",
        "# generator\n",
        "def genBlock(inp, out): # generator block with the size of input and the size of the output\n",
        "  return nn.Sequential( # basically set a number of layers that are gonna be executed sequentially\n",
        "      nn.Linear(inp, out), # a linear computation between input and output\n",
        "      nn.BatchNorm1d(out), # 1D because we are using black & white and one dimemsioal images with a single channel, normalise the values that are coming from the previous layer\n",
        "      nn.ReLU(inplace = True) # add non-linearity: in order to learn more complex functions\n",
        "  )\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, z_dim = 64, i_dim = 784, h_dim = 128): # latent vector, output image size 28x28=784, base size of the hidden layer of the generator\n",
        "    super().__init__()\n",
        "    self.gen = nn.Sequential(\n",
        "        genBlock(z_dim, h_dim), # 64 -> 128\n",
        "        genBlock(h_dim, h_dim * 2), # 128 -> 256 we want to increase the size\n",
        "        genBlock(h_dim * 2, h_dim * 4), # 256 -> 512 incresing the size\n",
        "        genBlock(h_dim * 4, h_dim * 8), # 512 -> 1024\n",
        "        nn.Linear(h_dim * 8, i_dim), # 1024 -> 784(28x28) we want to create an image with the same size of the MNIST images\n",
        "        nn.Sigmoid() # set values [0,1]\n",
        "    )\n",
        "\n",
        "  def forward(self, noise): # the function that is gonna be executed when we basically run the instance of the class\n",
        "    return self.gen(noise)\n",
        "\n",
        "def gen_noise(number, z_dim): # the function that generates noise\n",
        "  return torch.randn(number, z_dim).to(device) # returns a tensor field with random numbers from a normal dist. with mean of 0 and variance of 1 (standard normal distribution)\n",
        "\n",
        "############################# ##########################\n",
        "\n",
        "# discriminator\n",
        "def discBlock(inp, out): # like generator\n",
        "  return nn.Sequential(\n",
        "    nn.Linear(inp, out),\n",
        "    nn.LeakyReLU(0.2, inplace = True) # instead of giving 0 to negative values give them a small negative value on a slope\n",
        "  )\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, i_dim = 784, h_dim = 256):\n",
        "    super().__init__()\n",
        "    self.disc = nn.Sequential(\n",
        "        discBlock(i_dim, h_dim * 4), # 784 -> 1024\n",
        "        discBlock(h_dim * 4, h_dim * 2), # 1024 - > 512\n",
        "        discBlock(h_dim * 2, h_dim), # 512 -> 256\n",
        "        nn.Linear(h_dim, 1) # 256 -> 1\n",
        "    )\n",
        "  def forward(self, image): # takes the image\n",
        "    return self.disc(image) # result of passing that image to the discriminator module\n"
      ],
      "metadata": {
        "id": "PfVDOPjkKD_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen = Generator(z_dim).to(device) # declare the generator\n",
        "gen_opt = torch.optim.Adam(gen.parameters(), lr = lr) # declare the optimiser for the generator\n",
        "\n",
        "disc = Discriminator().to(device) # declare the discriminator\n",
        "disc_opt = torch.optim.Adam(disc.parameters(), lr = lr) # declare the optimiser for the discriminator"
      ],
      "metadata": {
        "id": "4AXvN4myUYBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen # see what is inside in the Generator"
      ],
      "metadata": {
        "id": "vCVq2m0XupZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "disc # see what is inside in the Discriminator"
      ],
      "metadata": {
        "id": "C0jw9U29uy4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = next(iter(dataloader)) # iterator to get the next batch, dataloader will give the 128 images each iteration\n",
        "print(x.shape) # 128 x 1 x 28 x 28\n",
        "print(y.shape) # 128\n",
        "print(y[:10]) #print first 10 values in the images"
      ],
      "metadata": {
        "id": "iMPjpcv1vM6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noise = gen_noise(bs, z_dim) # batch size: 128, z_dim: 64\n",
        "fake = gen(noise) # pass the noise to the Generator\n",
        "show_tensor_images(fake) # show the fake image\n",
        "# this is the initial output of passing the noise through the generator.\n",
        "# because the generator did not begin to learn, it produces a very noisy output."
      ],
      "metadata": {
        "id": "kV7AMU4_yhkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Â calculating the loss\n",
        "\n",
        "# generator loss\n",
        "def calc_gen_loss(loss_func, gen, disc, number, z_dim):\n",
        "  noise = gen_noise(number, z_dim) # get set of noise vectors\n",
        "  fake = gen(noise) # pass these vectors to generator\n",
        "  pred = disc(fake) # pass the output of the generator to the discriminator\n",
        "  targets = torch.ones_like(pred) # create a tensor wit the dimensionality of predictions, fill it with ones, that's the generator's goal actuall\n",
        "  gen_loss = loss_func(pred, targets) # compare the predictions and target values to fool the discriminator\n",
        "  return gen_loss\n",
        "\n",
        "# discriminator loss\n",
        "def calc_disc_loss(loss_func, gen, disc, number, real, z_dim):\n",
        "  noise = gen_noise(number, z_dim) # get set of noise vectors\n",
        "  fake = gen(noise) # pass these vectors to generator\n",
        "  disc_fake = disc(fake.detach()) # when pytorch backpropogates, the loss of the discriminator, we don't want to change the parameters of the generator when optimising the discriminator (detach)\n",
        "  disc_fake_targets = torch.zeros_like(disc_fake) # zeros: fake\n",
        "  disc_fake_loss = loss_func(disc_fake, disc_fake_targets) # compare the output of the dicriminator with the fake targets\n",
        "\n",
        "  disc_real = disc(real) # pass the real images to the discriminator\n",
        "  disc_real_targets = torch.ones_like(disc_real) # ones: real\n",
        "  disc_real_loss = loss_func(disc_real, disc_real_targets) # compare the output of the dicriminator with the real targets\n",
        "\n",
        "  disc_loss = (disc_fake_loss + disc_real_loss) / 2 # average the two losses\n",
        "  return disc_loss"
      ],
      "metadata": {
        "id": "ep2qakqjyo0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "\n",
        "# 60000 MNIST images / 128 size of each batch = 468.75 = 469 steps in each epoch\n",
        "# each step is going to process 128 images = size of the batch (except the last step)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for real, _ in tqdm(dataloader): # for the information that is returned at each point by the dataloader, wrapped by tqdm (a good bar visualisation)\n",
        "    # discriminator\n",
        "    disc_opt.zero_grad() # take the discriminator optimiser and set its gradients to zero\n",
        "\n",
        "    cur_bs = len(real) # current batch size at each step real:128 x 1 x 28 x 28 (except the last step)\n",
        "    real = real.view(cur_bs, -1) # 128 x 784 reshape the real images into the size of current batch size\n",
        "    real = real.to(device) # put the real images on the device\n",
        "\n",
        "    disc_loss = calc_disc_loss(loss_func, gen, disc, cur_bs, real, z_dim) # calculate the discriminator loss\n",
        "\n",
        "    disc_loss.backward(retain_graph = True) # backpropagate the loss to calculate all the gradients\n",
        "    disc_opt.step() # update the discriminator parameters\n",
        "\n",
        "############################# ##########################\n",
        "    # generator\n",
        "    gen_opt.zero_grad() # take the generator optimiser and set its gradients to zero\n",
        "\n",
        "    gen_loss = calc_gen_loss(loss_func, gen, disc, cur_bs, z_dim) # calculate the generator loss\n",
        "    gen_loss.backward(retain_graph = True) # backpropagate the loss to calculate all the gradients\n",
        "    gen_opt.step()\n",
        "\n",
        "    #Â visualisation & stats\n",
        "    mean_disc_loss += disc_loss.item() / info_step # mean discriminator loss\n",
        "    mean_gen_loss += gen_loss.item() / info_step # mean generator loss\n",
        "\n",
        "    # we want to show the information\n",
        "    if cur_step % info_step == 0 and cur_step > 0:\n",
        "      fake_noise = gen_noise(cur_bs, z_dim) # get noise vectors\n",
        "      fake = gen(fake_noise) # pass these vectors to generator\n",
        "      show_tensor_images(fake) # show the fake image\n",
        "      show_tensor_images(real) # show the real image\n",
        "      print(f\"Epoch {epoch}, step {cur_step}: Generator loss: {mean_gen_loss}, discriminator loss: {mean_disc_loss}\") # print everything\n",
        "      mean_gen_loss = 0 # reset the mean generator loss\n",
        "      mean_disc_loss = 0 # reset the mean discriminator loss\n",
        "    cur_step += 1 # increment the steps"
      ],
      "metadata": {
        "id": "qdnNZ1ZW0p4x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}