{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**mode collapse:** generator stuck in a single mode (peak of the distribution)\n",
        "\n",
        "**loss value meaning:** not a good correlation between the loss value and the quality of the generated results\n",
        "\n",
        "**bce loss problems -** flat gradients\n",
        "\n",
        "we'll use **the wasserstein loss** instead of binary cross entropy.\n",
        "\n",
        "**earth mover distance:** the effort needed to make both real and generated distributions equal."
      ],
      "metadata": {
        "id": "uEpXvJpNAhVU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1pqS17Ro9ZPN"
      },
      "outputs": [],
      "source": [
        "# coding an advanced GAN from scratch in python + pytorch\n",
        "# importing the libraries\n",
        "\n",
        "import torch, torchvision, os, PIL, pdb # pytorch and torchvision are for datasets and image transforms, os if for file handling, pil is for image processing, and pdb if for debugging\n",
        "from torch import nn # neural network module\n",
        "from torch.utils.data import Dataset # dataset class and data loader to create custom datasets and load them in batches\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms # transforms module from torchvision to apply image preprocessing\n",
        "from torchvision.utils import make_grid # function to create a grid of images for visualisation\n",
        "from tqdm.auto import tqdm # progress bar tool for loops\n",
        "import matplotlib.pyplot as plt # for plotting images and graphs\n",
        "import numpy as np # for numerical operations\n",
        "from PIL import Image # image module from pillow for image loading and handling"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show(tensor, num = 25, wandb = 0, name = ''):\n",
        "  data = tensor.detach().cpu()   # detach tensor from computation graph and move it to cpu\n",
        "  grid = make_grid(data[:num], nrow = 5).permute(1, 2, 0)   # create a grid of images (5 per row), rearrange axes for plotting\n",
        "\n",
        "  # optional: log images to wandb if enabled\n",
        "  if (wandb == 1 and wandbact ==1):\n",
        "    wandb.log({name: wandb.Image(grid.numpy().clip(0,1))})\n",
        "\n",
        "  plt.imshow(grid.clip(0, 1))\n",
        "  plt.show()\n",
        "\n",
        "  #hyperparameters and general parameters\n",
        "  n_epochs = 100000 # number of training iterations\n",
        "  batch_size = 128 # number of images per batch\n",
        "  lr = 1e-4 # learning rate for optimiser\n",
        "  z_dim = 200 # size of the noise vector for generator\n",
        "  device = 'cuda' # GPU for training\n",
        "\n",
        "  cur_step = 0 # current step in training\n",
        "  crit_cycles = 5 # number of critic updates per generator update (used in wgan)\n",
        "  gen_losses = [] # to track generator loss over time\n",
        "  crit_losses = [] # to track critic/discriminator loss over time\n",
        "  show_step = 35 # how often to display generated image\n",
        "  save_step = 35 # how often to display model check points\n",
        "\n",
        "  wandbact = 1 # yes we want to track stats through weights and biases, optional"
      ],
      "metadata": {
        "id": "My-ARoryrNFP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optional\n",
        "!pip install wandb\n",
        "import wandb\n",
        "wandb.login(key = 'YOUR KEY HERE')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ztz5VHQ_XU28",
        "outputId": "f33d70f9-199e-4e6f-ef9b-da41049592dd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.10)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.7)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.27.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mburciadilammermoore\u001b[0m (\u001b[33mburciadilammermoore-middle-east-technical-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "experiment_name = wandb.util.generate_id() # generate a unique id for the experiment\n",
        "\n",
        "myrun = wandb.init( # initialise a wandb run\n",
        "    project = 'wgan', # name of the project: wassersteing gan\n",
        "    group = experiment_name, # group name used to group related runs\n",
        "    config = { # configuration dictionary\n",
        "        'optimizer': 'sgd', # use stochastic gradient descent\n",
        "        'model': 'wgan gp', # model type is wasserstein gan with gradient penalty\n",
        "        'epoch': 1000, # traning epochs\n",
        "        'batch_size': 128 # samples per batch\n",
        "    }\n",
        ")\n",
        "\n",
        "config = wandb.config # store wand config for early access"
      ],
      "metadata": {
        "id": "SprUwf8albim"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(experiment_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBZP3ieMnN_e",
        "outputId": "bfb0eb14-ce33-4764-f573-f8872aa68ba1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "zkujyczk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generator model\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, z_dim = 64, d_dim = 16):\n",
        "    super(Generator, self).__init__()\n",
        "    self.z_dim = z_dim\n",
        "\n",
        "    self.gen = nn.Sequential(\n",
        "        ## ConvTranspose2d: in_channels, out_channels, kernel_size, stride = 1, padding = 0\n",
        "        ## calculating new width and height: ((n-1) * stride) - (2 * padding) + ks\n",
        "        ## n: width or height\n",
        "        ## ks: kernel size\n",
        "        nn.ConvTranspose2d (z_dim, d_dim * 32, 4, 1, 0 ), ## we begin with a 1x1 image with z_dim number of channels (200) --> 4x4 (ch: 200, 512)\n",
        "        nn.BatchNorm2d(d_dim * 32), # normalise values\n",
        "        nn.ReLU(inplace = True), # add non-linearity\n",
        "\n",
        "        nn.ConvTranspose2d (d_dim * 32, d_dim * 16, 4, 2, 1), ## 8x8 (ch: 512, 256)\n",
        "        nn.BatchNorm2d(d_dim * 16), # normalise values\n",
        "        nn.ReLU(inplace = True), # add non-linearity\n",
        "\n",
        "        nn.ConvTranspose2d (d_dim * 16, d_dim * 8, 4, 2, 1), ## 16x16 (ch: 256, 128) because ((n-1) * stride) - (2 * padding) + ks = ((8-1) * 2) - (2 * 1) + 4) = 16\n",
        "        nn.BatchNorm2d(d_dim * 8), # normalise values\n",
        "        nn.ReLU(inplace = True), # add non-linearity\n",
        "\n",
        "        nn.ConvTranspose2d (d_dim * 8, d_dim * 4, 4, 2, 1), ## 32x32 (ch: 128, 64)\n",
        "        nn.BatchNorm2d(d_dim * 4), # normalise values\n",
        "        nn.ReLU(inplace = True), # add non-linearity\n",
        "\n",
        "        nn.ConvTranspose2d (d_dim * 4, d_dim * 2, 4, 2, 1), ## 64x64 (ch: 64, 32)\n",
        "        nn.BatchNorm2d(d_dim * 2), # normalise values\n",
        "        nn.ReLU(inplace = True), # add non-linearity\n",
        "\n",
        "        nn.ConvTranspose2d (d_dim * 2, 3, 4, 2, 1), ## 128x128 (ch: 32, 3)\n",
        "        nn.Tanh() # add non-linearity, produce result in the range from -1 to 1\n",
        "\n",
        "    )\n",
        "\n",
        "  def forward(self, noise):\n",
        "    x = noise.view(len(noise), self.z_dim, 1, 1) # reshape noise to (batch_size, z_dim, 1, 1) ---> 128 x 200 x 1 x 1\n",
        "    return self.gen(x)\n",
        "\n",
        "\n",
        "def gen_noise(num, z_dim, device = 'cuda'):\n",
        "  return torch.randn(num, z_dim, device = device) # set of noise vectors of 128 x 200"
      ],
      "metadata": {
        "id": "yzxwR-qYqLvh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " nn.Conv2d ## (n + (2 * padding) - ks) // stride + 1"
      ],
      "metadata": {
        "id": "19XEkUtD2ntV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}